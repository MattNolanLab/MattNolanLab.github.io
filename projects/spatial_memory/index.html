<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Spatial Memory | Nolan &amp; Sürmeli Lab </title> <meta name="author" content="Nolan &amp; Sürmeli"> <meta name="description" content="The Nolan x Surmelli Lab website. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A7%A0&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mattnolanlab.github.io/projects/spatial_memory/"> </head> <body class=" sticky-bottom-footer"> <header> <div class="container"> <img src="/assets/img/banner.png" class="banner" alt="Banner Image" style="width: 100%; height: auto;"> </div> <nav id="navbar" class="navbar container navbar-light navbar-expand-sm sticky-top" role="navigation"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">research </a> </li> <li class="nav-item "> <a class="nav-link" href="/manual/">manual </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/data-and-code/">data &amp; code </a> </li> <li class="nav-item "> <a class="nav-link" href="/people-nolan/">Nolan group </a> </li> <li class="nav-item "> <a class="nav-link" href="/people-surmeli/">Sürmeli group </a> </li> </ul> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Spatial Memory</h1> <p class="post-description"></p> </header> <article> <h2 id="the-neural-map">The Neural Map</h2> <p>Just a note that we can add citations like this <a class="citation" href="#WOS:000878031400006">(Tennant et al., 2022)</a>.</p> <p>Our sense of navigation is not something we tend to consider too deeply in our day-to-day lives. Nevertheless, we somehow have a subconscious knowledge of were we are in the world and where we are going. We use it everywhere - to walk home, to go to the grocery store, to walk to the bathroom in the middle of the night.</p> <p>How we navigate is largely dependent on what information is available to us. The brain is complex and uses a variety of strategies to determine our position, relative to other landmarks and to start or goal locations. Among those is beaconing, a strategy where we use a distant object to navigate to - say, “Hey, there’s a neon sign here saying ‘Pub’” - that’s probably the entrance to the pub. But what if you don’t have those clues?</p> <p>This is where path integration comes in.</p> <hr> <h2 id="path-integration">Path Integration</h2> <p>Say you’re out on a hike with your friends. You’re full of energy during the day and make plenty of detours before you get to the campsite and settle in for a restful night, listening to the soothing patter of rain on the tent. Oh no! It’s 2am and you’re woken up in what an optimist would call a ‘puddle’, and anyone else might label ‘a decidedly sizable body of water’.</p> <p><em>So much for the guy on Facebook Marketplace promising that the tent was waterproof.</em></p> <p>You and your friend make the decision to trek back to the car park. You wish one of you had brought a headlamp at least - you can’t use any landmarks to navigate. Despite that, you somehow manage to make it back in one piece, going straight from the campsite to the carpark without any of the diversions you had undertaken on the way there. <em>How?</em></p> <div class="post"> <div id="gameCanvas1"></div> </div> <p>Two types of sensory information are required to update where we think we are: <em>Allothetic information</em> we get from the outside environment, like that ‘Pub’ sign. <em>Idiothetic information</em> is generated by the body itself. For example, the brain signals responsible for walking to the pub also provide us with information about how far we’ve walked so far. Path integration uses these idiothetic cues to transverse the mental map in our head. For example, a mouse that is foraging and takes a long, winding trajectory towards its goal will have ‘calculated’ its displacement from its nest and can make a beeline safely back if it suddenly runs into a fox.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/game/mouse_integration-480.webp 480w,/assets/img/game/mouse_integration-800.webp 800w,/assets/img/game/mouse_integration-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/game/mouse_integration.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="mouse integration" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Studying path integration is complicated by the fact that it’s only one part of the mechanism behind navigation. It’s an error-prone system, and so it works in combination with other information to create a path - for example, a mouse might use remembered landmarks, olfaction and even way-marking to navigate through an environment. Studying the neurons specifically involved in path integration therefore requires us to remove all other possibilities but using path integration. How do we do <em>that?</em></p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/game/pi_exp_1-480.webp 480w,/assets/img/game/pi_exp_1-800.webp 800w,/assets/img/game/pi_exp_1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/game/pi_exp_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="pi 1" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>One way of studying path integration is using virtual reality. Mice run through a VR corridor on a treadmill until there’s a visual cue. If they stop at the visual cue, they get a treat. After a few repetitions, the visual cue is removed - yet the mice still stop in the place where the visual cue <em>would have been</em>. If there are no external cues for the mice to see, how do they know when to stop?</p> <p>The mice can’t use other navigational strategies, such as beaconing, because there’s no allothetic cues, so they’re left with path integration. They might have remembered the time it took to run to the reward zone - but when the speed of the treadmill was changed, the mice didn’t overshoot the reward zone, despite running faster. This implies they weren’t measuring the time, but were instead getting their information from a collection of self-motion cues. This includes proprioception (the sense of your self-position and self-movement) along with the vestibular system (your inner ear, which provides a sense of balance and awareness of our head and body in space) and motor efference. Over longer distances, the accuracy of this system drops without external input such as landmarks, as small errors start to accumulate and the mice start to stop further away from the reward zone.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/game/pi_exp_2-480.webp 480w,/assets/img/game/pi_exp_2-800.webp 800w,/assets/img/game/pi_exp_2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/game/pi_exp_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="pi 1" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="cell-types">Cell types</h2> <p>Path integration is just one of the many navigational strategies we want to study to understand the basis of the neural map. There are many specialised cell types involved in navigation. For the purpose of this website, let’s focus on three: place cells, grid cells, and head direction cells.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/game/cell_types-480.webp 480w,/assets/img/game/cell_types-800.webp 800w,/assets/img/game/cell_types-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/game/cell_types.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="cell types" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>Grid cells</strong> are place-modulated neurons located primarily in the entorhinal cortex that fire periodically in space, mapping a triangular grid across an environment. As an animal moves through space, grid cells fire to create hexagonal patterns that allow us to map this space. Again, a population of grid cells alone can encode a spatial map</p> <p><strong>Place cells</strong> located in the hippocampus, fire when an animal enters a specific location in space. A population of place cells alone can encode a spatial map.</p> <p><strong>Head direction cells</strong> are primarily found in the postsubiculum, and provide directional information by preferentially firing in specific directions. A population of head direction cells can encode which direction you are facing in your spatial map.</p> <p>These cells potentially have uses outside of encoding physical space - their coding mechanism may be used for more general problem sets, such as cognitive mapping. Cognitive mapping refers to swapping out the three-dimensional world we interact with for a different, continuous dimension that represents an abstract concept. The same way we might encode the map of our room, we might use the hexagonal-firing properties of grid cells to represent, for example, conceptual spaces, such as hierarchically organizing ideas within our brain, or recording temporal sequences of events.</p> <hr> <script src="https://cdn.jsdelivr.net/npm/phaser@3.60.0/dist/phaser-arcade-physics.min.js"></script> <script type="module" src="/kaja_game/js/main.js"></script> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge" style="background-color:#d63230"><a href="">NOLAN</a></abbr> </div> <div id="WOS:000878031400006" class="col-sm-8"> <div class="title">Spatial representation by ramping activity of neurons in the retrohippocampal cortex</div> <div class="author"> Sarah A. Tennant ,  Harry Clark ,  Ian Hawes , and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Wing Kin Tam, Junji Hua, Wannan Yang, Klara Z. Gerlei, Emma R. Wood, Matthew F. Nolan' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> Oct 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Neurons in the retrohippocampal cortices play crucial roles in spatial memory. Many retrohippocampal neu-rons have firing fields that are selectively active at specific locations, with memory for rewarded locations associated with reorganization of these firing fields. Whether this is the sole strategy for representing spatial memories is unclear. Here, we demonstrate that during a spatial memory task retrohippocampal neurons encode location through ramping activity that extends across segments of a linear track approaching and following a reward, with the rewarded location represented by offsets or switches in the slope of the ramping activity. Ramping representations could be maintained independently of trial outcome and cues marking the reward location, indicating that they result from recall of the track structure. When recorded in an open arena, neurons that generated ramping activity during the spatial memory task were more numerous than grid or border cells, with a majority showing spatial firing that did not meet criteria for classification as grid or border representations. Encoding of rewarded locations through offsets and switches in the slope of ramping activ-ity also emerged in recurrent neural network models trained to solve a similar spatial memory task. Impaired performance of model networks following disruption of outputs from ramping neurons is consistent with this coding strategy supporting navigation to recalled locations of behavioral significance. Our results suggest that encoding of learned spaces by retrohippocampal networks employs both discrete firing fields and continuous ramping representations. We hypothesize that retrohippocampal ramping activity mediates readout of learned models for goal-directed navigation.</p> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 Nolan &amp; Sürmeli. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>